{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Embedding, LSTM\n",
    "from keras.utils import np_utils\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.preprocessing import sequence\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "path = get_file('alice.txt', origin=\"http://www.gutenberg.org/cache/epub/11/pg11.txt\")\n",
    "doc = open(path).readlines()[0:50]\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(doc)\n",
    "doc = tokenizer.texts_to_sequences(doc)\n",
    "doc = [l for l in doc if len(l) > 1]\n",
    "words_size = sum([len(words) - 1 for words in doc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "maxlen = max([len(x)-1 for x in doc])\n",
    "vocab_size = len(tokenizer.word_index)+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_data(X, maxlen, V):\n",
    "    for sentence in X: \n",
    "        inputs = []\n",
    "        targets = []\n",
    "        for i in range(1, len(sentence)):\n",
    "            inputs.append(sentence[0:i])\n",
    "            targets.append(sentence[i])\n",
    "        y = np_utils.to_categorical(targets, V)\n",
    "        inputs_sequence = sequence.pad_sequences(inputs, maxlen=maxlen)\n",
    "        yield (inputs_sequence, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def sample(p):\n",
    "    p /= sum(p)\n",
    "    return np.where(np.random.multinomial(1,p,1)==1)[1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nb_units = 128\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, nb_units, input_length=maxlen))\n",
    "model.add(LSTM(nb_units, return_sequences=False))\n",
    "model.add(Dense(vocab_size))\n",
    "model.add(Activation('softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adadelta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 alice's on thought ' gutenberg's gutenberg's date release so reading well made up millennium was\n",
      "1 alice's peeped what lewis 0 cost get by very 11 online this in cost by\n",
      "2 alice's whatsoever 'without no included online www feel as of into but i license is\n",
      "3 alice's making last worth fulcrum what whether whether whatsoever what ' use for may millennium\n",
      "4 alice's book beginning well 3 considering thought and gutenberg's had her stupid 0 is 25\n",
      "5 alice's march ' org a for the pictures 'without for i of english beginning down\n",
      "6 alice's 2008 in lewis mind you no gutenberg's carroll she sleepy the mind would may\n",
      "7 alice's in fulcrum rabbit the it updated chain alice's 2011 ' 25 considering carroll december\n",
      "8 alice's restrictions lewis the author sleepy lewis had for as into english release had '\n",
      "9 alice's the adventures december her i to get carroll 2008 of was sister peeped chain\n",
      "10 alice's her terms the well by chain ebook she get be it updated it had\n",
      "11 alice's the beginning use ' ' by wonderland 0 online her 11 daisy trouble 1994\n",
      "12 alice's sleepy carroll march carroll project date carroll may do project edition her 0 anywhere\n",
      "13 alice's english ' hole but the included the ' license at org gutenberg and of\n",
      "14 alice's own gutenberg rabbit gutenberg's sleepy of made making a the terms 11 carroll away\n",
      "15 alice's ' book tired and adventures of alice no the daisy chain gutenberg's www and\n",
      "16 alice's 1994 ' adventures lewis ' as ' and the gutenberg's was 2011 up her\n",
      "17 alice's adventures in wonderland wonderland online she 3 use sleepy adventures the wonderland the almost\n",
      "18 alice's to date 3 made she no license 2011 the once this pictures or of\n",
      "19 alice's adventures in own lewis lewis 25 whatsoever get get for of under do and\n",
      "20 alice's english twice i was ' ebook 11 i mind get trouble of this she\n",
      "21 alice's adventures in 0 no worth lewis the and www of the gutenberg away up\n",
      "22 alice's adventures in wonderland by edition for project she 25 her had be and what\n",
      "23 alice's adventures in wonderland use the by in her march lewis carroll ' the could\n",
      "24 alice's adventures in wonderland wonderland sleepy pictures and sleepy and the the online the of\n",
      "25 alice's in wonderland could feel ' as date a gutenberg's for the pleasure the for\n",
      "26 alice's adventures in wonderland her 1994 what as and well or the the of org\n",
      "27 alice's into this was it or it or away into 'without had peeped 'without or\n",
      "28 alice's adventures of wonderland mind very 1994 getting and she she very the the peeped\n",
      "29 alice's in her get as had it or conversations 11 in she pleasure of the\n"
     ]
    }
   ],
   "source": [
    "for i in range(30):\n",
    "    for x, y in generate_data(doc, maxlen, vocab_size):\n",
    "        model.train_on_batch(x, y)\n",
    "\n",
    "    in_words = \"alice's\"\n",
    "    for _ in range(maxlen):\n",
    "        in_sequence = sequence.pad_sequences(tokenizer.texts_to_sequences([in_words]), maxlen=maxlen)\n",
    "        wordid = sample(model.predict(in_sequence)[0])\n",
    "        for k, v in tokenizer.word_index.items():\n",
    "            if v == wordid:\n",
    "                in_words += \" \" + k\n",
    "                break\n",
    "\n",
    "    print(i, in_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alice's adventures in wonderland by lewis carroll ' as ' the trouble of the the\n"
     ]
    }
   ],
   "source": [
    "in_words = \"alice's\"\n",
    "for _ in range(maxlen):\n",
    "    in_sequence = sequence.pad_sequences(tokenizer.texts_to_sequences([in_words]), maxlen=maxlen)\n",
    "    wordid = model.predict_classes(in_sequence, verbose=0)[0] # 最尤推定\n",
    "    for k, v in tokenizer.word_index.items():\n",
    "        if v == wordid:\n",
    "            in_words += \" \" + k\n",
    "            break\n",
    "\n",
    "print(in_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  },
  "toc": {
   "toc_cell": false,
   "toc_number_sections": true,
   "toc_threshold": 6,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
