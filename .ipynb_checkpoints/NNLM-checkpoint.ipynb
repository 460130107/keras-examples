{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Embedding, LSTM\n",
    "from keras.utils import np_utils\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.preprocessing import sequence\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "path = get_file('alice.txt', origin=\"http://www.gutenberg.org/cache/epub/11/pg11.txt\")\n",
    "doc = open(path).readlines()[0:50]\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(doc)\n",
    "doc = tokenizer.texts_to_sequences(doc)\n",
    "doc = [l for l in doc if len(l) > 1]\n",
    "words_size = sum([len(words) - 1 for words in doc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "maxlen = max([len(x)-1 for x in doc])\n",
    "vocab_size = len(tokenizer.word_index)+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_data(X, maxlen, V):\n",
    "    for sentence in X: \n",
    "        inputs = []\n",
    "        targets = []\n",
    "        for i in range(1, len(sentence)):\n",
    "            inputs.append(sentence[0:i])\n",
    "            targets.append(sentence[i])\n",
    "            y = np_utils.to_categorical(targets, V)\n",
    "        inputs_sequence = sequence.pad_sequences(inputs, maxlen=maxlen)\n",
    "        yield (inputs_sequence, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def sample(p):\n",
    "    p /= sum(p)\n",
    "    return np.where(np.random.multinomial(1,p,1)==1)[1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nb_units = 128\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, nb_units, input_length=maxlen))\n",
    "model.add(LSTM(nb_units, return_sequences=False))\n",
    "model.add(Dense(vocab_size))\n",
    "model.add(Activation('softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adadelta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 alice's reading tired by well well ' beginning sleepy so start could posting do use\n",
      "1 alice's away you pleasure chain mind very had org org very in chain very 11\n",
      "2 alice's made she give you would rabbit a under 3 away may considering sister give\n",
      "3 alice's included but into ' 2008 you reading daisy cost by carroll for get twice\n",
      "4 alice's at own making sitting stupid ' pleasure up of adventures and 0 you or\n",
      "5 alice's for what into included language the alice updated ' it posting cost worth whatsoever\n",
      "6 alice's 11 project she wonderland is online worth carroll project getting ' nothing get in\n",
      "7 alice's 11 ' project included december alice's daisy and of day she stupid lewis considering\n",
      "8 alice's worth thought the 2008 fulcrum was her carroll of of for a 2011 getting\n",
      "9 alice's at pictures it conversations the mind own i was mind down she use is\n",
      "10 alice's away ' stupid as at the 'and december adventures this sister wonderland a edition\n",
      "11 alice's get the 3 june terms her pleasure you and org whatsoever 20 anyone fulcrum\n",
      "12 alice's adventures in beginning fulcrum updated 11 and making and mind trouble carroll org tired\n",
      "13 alice's 3 updated ' of very or of her making of no it or www\n",
      "14 alice's adventures use in considering gutenberg down worth of could restrictions terms org lewis online\n",
      "15 alice's adventures in was wonderland 'and conversations of project adventures in lewis fulcrum carroll of\n",
      "16 alice's as was but peeped mind is 2008 by wonderland the project org it the\n",
      "17 alice's ' as carroll ' 'and conversations and her ' 11 for this 11 the\n",
      "18 alice's the carroll ' making the online as ' getting license own license the 'and\n",
      "19 alice's was in very of as book very ebook and up and and up the\n",
      "20 alice's adventures in wonderland by very by ' carroll lewis of may millennium down it\n",
      "21 alice's adventures in wonderland by 2008 by adventures 25 in wonderland millennium as down as\n",
      "22 alice's adventures in her a get ' stupid ' could the of book under away\n",
      "23 alice's adventures adventures in wonderland by date march 20 date getting and millennium copy '\n",
      "24 alice's adventures in wonderland carroll the very in and once sleepy the 1994 own the\n",
      "25 alice's ' lewis carroll ' is the december 1994 no march pictures had she and\n",
      "26 alice's adventures in wonderland sleepy updated copy december rabbit get english 3 no conversations her\n",
      "27 alice's adventures her wonderland carroll lewis carroll 1994 march 2008 in her the daisy with\n",
      "28 alice's adventures in wonderland by english date the beginning the copy a get it 0\n",
      "29 alice's adventures her i very the use project trouble a org alice own conversations and\n"
     ]
    }
   ],
   "source": [
    "for i in range(30):\n",
    "    for x, y in generate_data(doc, maxlen, vocab_size):\n",
    "        model.train_on_batch(x, y)\n",
    "\n",
    "    in_words = \"alice's\"\n",
    "    for _ in range(maxlen):\n",
    "        in_sequence = sequence.pad_sequences(tokenizer.texts_to_sequences([in_words]), maxlen=maxlen)\n",
    "        wordid = sample(model.predict(in_sequence)[0])\n",
    "        for k, v in tokenizer.word_index.items():\n",
    "            if v == wordid:\n",
    "                in_words += \" \" + k\n",
    "                break\n",
    "\n",
    "    print(i, in_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alice's adventures in wonderland by lewis carroll march 1994 the use of a book '\n"
     ]
    }
   ],
   "source": [
    "in_words = \"alice's\"\n",
    "for _ in range(maxlen):\n",
    "    in_sequence = sequence.pad_sequences(tokenizer.texts_to_sequences([in_words]), maxlen=maxlen)\n",
    "    wordid = model.predict_classes(in_sequence, verbose=0)[0] # 最尤推定\n",
    "    for k, v in tokenizer.word_index.items():\n",
    "        if v == wordid:\n",
    "            in_words += \" \" + k\n",
    "            break\n",
    "\n",
    "print(in_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
